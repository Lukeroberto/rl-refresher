{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "from gym.spaces.utils import flatdim\n",
    "import torch as pt\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Comment out for debugging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_video(ep_number: int):\n",
    "    video = io.open(f\"./gym-results/rl-video-episode-{ep_number}.mp4\", 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    return HTML(data='''\n",
    "        <video width=\"360\" height=\"auto\" alt=\"test\" controls><source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" /></video>'''\n",
    "    .format(encoded.decode('ascii')))\n",
    "\n",
    "def smooth(y, box_pts):\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    y_smooth = np.convolve(y, box, mode='valid')\n",
    "    return y_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 935.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Rewards over 2 episodes')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(\"ALE/Pong-v5\")\n",
    "env = wrappers.RecordVideo(env, \"./gym-results\", new_step_api=True)\n",
    "env.reset(seed=42)\n",
    "\n",
    "# hyperparams\n",
    "num_steps = 1000\n",
    "random_rewards = [0]\n",
    "random_lengths = [0]\n",
    "ep_len = 0\n",
    "for _ in trange(num_steps):\n",
    "   action = env.action_space.sample() \n",
    "   observation, reward, done, info, _ = env.step(action)\n",
    "\n",
    "   if done:\n",
    "      random_rewards.append(reward)\n",
    "      random_lengths.append(ep_len)\n",
    "      observation = env.reset()\n",
    "      ep_len = 0\n",
    "   \n",
    "   ep_len += 1\n",
    "env.close()\n",
    "\n",
    "plt.plot(smooth(random_rewards, 200))\n",
    "plt.title(f\"Rewards over {len(random_rewards)} episodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "# Several useful wrapper environments\n",
    "class FireResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env=None):\n",
    "        super(FireResetEnv, self).__init__(env)\n",
    "        assert env.unwrapped.get_action_meanings()[1] == 'FIRE'\n",
    "        assert len(env.unwrapped.get_action_meanings()) >= 3\n",
    "    \n",
    "    def step(self, action):\n",
    "        return self.env.step(action)\n",
    "       \n",
    "def reset(self):\n",
    "    self.env.reset()\n",
    "    obs, _, done, _ = self.env.step(1)\n",
    "    if done:\n",
    "        self.env.reset()\n",
    "    obs, _, done, _ = self.env.step(2)\n",
    "    if done:\n",
    "        self.env.reset()\n",
    "    return obs\n",
    "\n",
    "class MaxAndSkipEnv(gym.Wrapper):\n",
    "    def __init__(self, env=None, skip=4):\n",
    "        super(MaxAndSkipEnv, self).__init__(env)\n",
    "        self._obs_buffer = collections.deque(maxlen=2)\n",
    "        self._skip = skip\n",
    "        \n",
    "    def step(self, action):\n",
    "        total_reward = 0.0\n",
    "        done = None\n",
    "        for _ in range(self._skip):\n",
    "           obs, reward, done, info, _ = self.env.step(action)\n",
    "           self._obs_buffer.append(obs)\n",
    "           total_reward += reward\n",
    "           if done:\n",
    "               break\n",
    "        max_frame = np.max(np.stack(self._obs_buffer), axis=0)\n",
    "        return max_frame, total_reward, done, info, _\n",
    "\n",
    "    def reset(self):\n",
    "       self._obs_buffer.clear()\n",
    "       obs = self.env.reset()\n",
    "       self._obs_buffer.append(obs)\n",
    "       return obs\n",
    "\n",
    "# TODO: Still produces broken ball and split user paddle\n",
    "class ProcessFrame84(gym.ObservationWrapper):\n",
    "    def __init__(self, env=None):\n",
    "        super(ProcessFrame84, self).__init__(env)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, \n",
    "                            shape=(84, 84, 1), dtype=np.uint8)\n",
    "    \n",
    "    def observation(self, obs):\n",
    "        return ProcessFrame84.process(obs)\n",
    "         \n",
    "    @staticmethod\n",
    "    def process(frame):\n",
    "        if frame.size == 210 * 160 * 3:\n",
    "            img = np.reshape(frame, [210, 160,  3]).astype(np.float32)\n",
    "        elif frame.size == 250 * 160 * 3:\n",
    "            img = np.reshape(frame, [250, 160, 3]).astype(np.float32)\n",
    "        else:\n",
    "            assert False, \"Unknown resolution.\" \n",
    "\n",
    "        img = img[:, :, 0] * 0.299 + img[:, :, 1] * 0.587 + img[:, :, 2] * 0.114\n",
    "        resized_screen = cv2.resize(img, (84, 110),            \n",
    "                        interpolation=cv2.INTER_AREA)\n",
    "        x_t = resized_screen[16:100, :] # remove scoreboard + bottom\n",
    "        x_t = np.reshape(x_t, [84, 84, 1])\n",
    "        return x_t.astype(np.uint8)\n",
    "\n",
    "class ImageToPyTorch(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super(ImageToPyTorch, self).__init__(env)\n",
    "        old_shape = self.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0,            \n",
    "                                shape=(old_shape[-1], \n",
    "                                old_shape[0], old_shape[1]),\n",
    "                                dtype=np.float32)\n",
    "    def observation(self, observation):\n",
    "      return np.moveaxis(observation, 2, 0)\n",
    "\n",
    "# Stacks several frames together\n",
    "class BufferWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env, n_steps, dtype=np.float32):\n",
    "        super(BufferWrapper, self).__init__(env)\n",
    "        self.dtype = dtype\n",
    "        old_space = env.observation_space\n",
    "        self.observation_space = \\\n",
    "                 gym.spaces.Box(old_space.low.repeat(n_steps, \n",
    "                 axis=0),old_space.high.repeat(n_steps, axis=0),     \n",
    "                 dtype=dtype)\n",
    "    def reset(self):\n",
    "        self.buffer = np.zeros_like(self.observation_space.low,\n",
    "        dtype=self.dtype)\n",
    "        return self.observation(self.env.reset())\n",
    "        \n",
    "    def observation(self, observation):\n",
    "        self.buffer[:-1] = self.buffer[1:]\n",
    "        self.buffer[-1] = observation\n",
    "        return self.buffer\n",
    "\n",
    "class ScaledFloatFrame(gym.ObservationWrapper):\n",
    "     def observation(self, obs):\n",
    "         return np.array(obs).astype(np.float32) / 255.0\n",
    "\n",
    "def make_pong():\n",
    "   env = gym.make(\"ALE/Pong-v5\")\n",
    "   env = wrappers.RecordVideo(env, \"./gym-results\", new_step_api=True)\n",
    "   env = MaxAndSkipEnv(env)\n",
    "   env = FireResetEnv(env)\n",
    "   env = ProcessFrame84(env)\n",
    "   env = ImageToPyTorch(env)\n",
    "   env = BufferWrapper(env, 4)\n",
    "   env = ScaledFloatFrame(env)\n",
    "\n",
    "   return env\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class QNet(nn.Module):\n",
    "    def __init__(self, obs_space, act_space):\n",
    "        super(QNet, self).__init__()\n",
    "        self.obs_shape = obs_space.low.shape\n",
    "        self.act_shape = flatdim(act_space)\n",
    "        self.replay_memory = []\n",
    "\n",
    "        self.conv1 = nn.Conv2d(self.obs_shape[0], 16, 8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 4, stride=2)\n",
    "        self.fc1 = nn.Linear(2592, 256) # mathemagic\n",
    "        self.out = nn.Linear(256, self.act_shape)\n",
    "\n",
    "        self.optimizer = pt.optim.Adam(self.parameters())\n",
    "        self.loss = nn.HuberLoss()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = nn.Flatten()(x)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        return self.out(x)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(q_vals, epsilon=0.1):\n",
    "    if pt.rand(1) < 0:\n",
    "        return pt.rand_like(q_vals)\n",
    "    \n",
    "    return pt.argmax(q_vals)\n",
    "\n",
    "class ReplayMemory():\n",
    "    def __init__(self, size, obs_space, act_shape):\n",
    "        self.size = size\n",
    "        self.counter = 0\n",
    "\n",
    "        obs_shape = obs_space.shape\n",
    "\n",
    "        self.obs = np.zeros((size, *obs_shape))\n",
    "        self.actions = np.zeros((size))\n",
    "        self.rewards = np.zeros((size))\n",
    "        self.obs_n = np.zeros((size, *obs_shape))\n",
    "        self.done = np.zeros((size))\n",
    "    \n",
    "    def store_transition(self, obs, action, obs_n, r, done):\n",
    "        indx = self.counter % self.size\n",
    "\n",
    "        self.obs[indx] = obs\n",
    "        self.actions[indx] = action\n",
    "        self.rewards[indx] = r\n",
    "        self.obs_n[indx] = obs_n\n",
    "        self.done[indx] = done\n",
    "\n",
    "        self.counter += 1\n",
    "    \n",
    "    def sample_batch(self, batch_size):\n",
    "        max_mem = min(self.counter, self.size)\n",
    "        batch = np.random.choice(max_mem, batch_size, replace=False)\n",
    "\n",
    "        obs = pt.from_numpy(self.obs[batch]).float()\n",
    "        actions = pt.from_numpy(self.actions[batch]).long()\n",
    "        rewards = pt.from_numpy(self.rewards[batch]).float()\n",
    "        obs_n = pt.from_numpy(self.obs_n[batch]).float()\n",
    "        terminal = pt.from_numpy(self.done[batch]).bool()\n",
    "\n",
    "        return obs, actions, rewards, obs_n, terminal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QNet(\n",
      "  (conv1): Conv2d(4, 16, kernel_size=(8, 8), stride=(4, 4))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))\n",
      "  (fc1): Linear(in_features=2592, out_features=256, bias=True)\n",
      "  (out): Linear(in_features=256, out_features=6, bias=True)\n",
      "  (loss): HuberLoss()\n",
      ")\n",
      "Storing transition: (4, 84, 84), 0, (4, 84, 84), 0.0, False\n",
      "Transition: tensor([0., 0., 0., 0., 0., 0.])\n",
      "All q-vals: tensor([[ 0.0589, -0.0327, -0.0576,  0.0552, -0.0230, -0.0022],\n",
      "        [ 0.0589, -0.0327, -0.0576,  0.0552, -0.0230, -0.0022],\n",
      "        [ 0.0589, -0.0327, -0.0576,  0.0552, -0.0230, -0.0022],\n",
      "        [ 0.0589, -0.0327, -0.0576,  0.0552, -0.0230, -0.0022],\n",
      "        [ 0.0589, -0.0327, -0.0576,  0.0552, -0.0230, -0.0022],\n",
      "        [ 0.0589, -0.0327, -0.0576,  0.0552, -0.0230, -0.0022]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test\n",
    "env = make_pong()\n",
    "obs = env.reset()\n",
    "memory = ReplayMemory(10, env.observation_space, env.action_space)\n",
    "\n",
    "dqn = QNet(env.observation_space, env.action_space)\n",
    "print(dqn)\n",
    "obs_n, r, done, _, _ = env.step(env.action_space.sample())\n",
    "\n",
    "# q_vals = dqn(pt.tensor(obs))\n",
    "# action = epsilon_greedy(q_vals)\n",
    "action = 0\n",
    "\n",
    "print(f\"Storing transition: {obs.shape}, {action}, {obs_n.shape}, {r}, {done}\")\n",
    "memory.store_transition(obs, action, obs_n, r, done)\n",
    "memory.store_transition(obs, action, obs_n, r, done)\n",
    "memory.store_transition(obs, action, obs_n, r, done)\n",
    "memory.store_transition(obs, action, obs_n, r, done)\n",
    "memory.store_transition(obs, action, obs_n, r, done)\n",
    "memory.store_transition(obs, action, obs_n, r, done)\n",
    "states, actions, rewards, states_, dones = memory.sample_batch(6)\n",
    "print(f\"Transition: {rewards}\")\n",
    "q_vals = dqn(states)\n",
    "print(f\"All q-vals: {q_vals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Loss: 0.05440390855073929:   0%|          | 5/1001 [00:05<16:10,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([1000, 4, 84, 84]), torch.Size([1000, 4, 84, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Loss: 0.06196628510951996:   0%|          | 5/1001 [00:06<16:10,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([1000, 4, 84, 84]), torch.Size([1000, 4, 84, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Loss: 0.04936188831925392:   0%|          | 5/1001 [00:06<16:10,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([1000, 4, 84, 84]), torch.Size([1000, 4, 84, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Loss: 0.05004259571433067:   0%|          | 5/1001 [00:07<16:10,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([1000, 4, 84, 84]), torch.Size([1000, 4, 84, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Loss: 0.05203894525766373:   0%|          | 5/1001 [00:07<16:10,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([1000, 4, 84, 84]), torch.Size([1000, 4, 84, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Loss: 0.05167233198881149:   0%|          | 5/1001 [00:08<16:10,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([1000, 4, 84, 84]), torch.Size([1000, 4, 84, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Loss: 0.0512743815779686:   0%|          | 5/1001 [00:08<16:10,  1.03it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([1000, 4, 84, 84]), torch.Size([1000, 4, 84, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Loss: 0.05062419921159744:   0%|          | 5/1001 [00:09<16:10,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([1000, 4, 84, 84]), torch.Size([1000, 4, 84, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Loss: 0.049205705523490906:   0%|          | 5/1001 [00:09<16:10,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([1000, 4, 84, 84]), torch.Size([1000, 4, 84, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Loss: 0.048571862280368805:   0%|          | 5/1001 [00:10<16:10,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([1000, 4, 84, 84]), torch.Size([1000, 4, 84, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Loss: 0.04977418854832649:   0%|          | 5/1001 [00:10<16:10,  1.03it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([1000, 4, 84, 84]), torch.Size([1000, 4, 84, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Loss: 0.050075408071279526:   0%|          | 5/1001 [00:11<16:10,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([1000, 4, 84, 84]), torch.Size([1000, 4, 84, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Loss: 0.049538228660821915:   0%|          | 5/1001 [00:11<16:10,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([1000, 4, 84, 84]), torch.Size([1000, 4, 84, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Loss: 0.049068618565797806:   0%|          | 5/1001 [00:12<16:10,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([1000, 4, 84, 84]), torch.Size([1000, 4, 84, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Loss: 0.049027830362319946:   0%|          | 5/1001 [00:12<16:10,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([1000, 4, 84, 84]), torch.Size([1000, 4, 84, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Loss: 0.04883544147014618:   0%|          | 5/1001 [00:13<16:10,  1.03it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([1000, 4, 84, 84]), torch.Size([1000, 4, 84, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Loss: 0.049048393964767456:   0%|          | 5/1001 [00:13<16:10,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([1000, 4, 84, 84]), torch.Size([1000, 4, 84, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Loss: 0.04914326220750809:   0%|          | 5/1001 [00:13<16:10,  1.03it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([1000, 4, 84, 84]), torch.Size([1000, 4, 84, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Loss: 0.04910237342119217:   0%|          | 5/1001 [00:14<16:10,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([1000, 4, 84, 84]), torch.Size([1000, 4, 84, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Loss: 0.0493633896112442:   0%|          | 5/1001 [00:15<16:10,  1.03it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([1000, 4, 84, 84]), torch.Size([1000, 4, 84, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Loss: 0.04914088174700737:   0%|          | 5/1001 [00:15<16:10,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([1000, 4, 84, 84]), torch.Size([1000, 4, 84, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Loss: 0.049090031534433365:   0%|          | 5/1001 [00:16<16:10,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([1000, 4, 84, 84]), torch.Size([1000, 4, 84, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Loss: 0.04917954280972481:   0%|          | 5/1001 [00:16<16:10,  1.03it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([1000, 4, 84, 84]), torch.Size([1000, 4, 84, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Loss: 0.049308452755212784:   0%|          | 5/1001 [00:17<16:10,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([1000, 4, 84, 84]), torch.Size([1000, 4, 84, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current Loss: 0.049308452755212784:   0%|          | 5/1001 [00:17<58:48,  3.54s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/luke/projects/rl-refresher/deep-q-learning/dqn.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luke/projects/rl-refresher/deep-q-learning/dqn.ipynb#X10sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     loss \u001b[39m=\u001b[39m Q\u001b[39m.\u001b[39mloss(q_target, q_pred)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luke/projects/rl-refresher/deep-q-learning/dqn.ipynb#X10sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     pbar\u001b[39m.\u001b[39mset_description(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCurrent Loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/luke/projects/rl-refresher/deep-q-learning/dqn.ipynb#X10sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luke/projects/rl-refresher/deep-q-learning/dqn.ipynb#X10sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     Q\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luke/projects/rl-refresher/deep-q-learning/dqn.ipynb#X10sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m update_freq \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/software/rl-env/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/software/rl-env/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Pseudocode from DQN Paper\n",
    "env = make_pong()\n",
    "\n",
    "# Hyperparams\n",
    "epsilon = 0.1\n",
    "batch_size = 1000\n",
    "update_freq = 100\n",
    "gamma = 0.99\n",
    "\n",
    "# Initialize Replay Memory to capacity N\n",
    "replay_capacity = 1000\n",
    "memory = ReplayMemory(replay_capacity, env.observation_space, env.action_space)\n",
    "\n",
    "# Initialize action-value Function Q with random weights\n",
    "Q = QNet(env.observation_space, env.action_space)\n",
    "T = QNet(env.observation_space, env.action_space)\n",
    "\n",
    "num_episodes = batch_size + 1\n",
    "pbar = tqdm(range(num_episodes))\n",
    "i = 0\n",
    "for ep in pbar:\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "\n",
    "        # Select action random action with prob epsilon, otherwise argmax_a Q(obs, a)\n",
    "        action = epsilon_greedy(Q(pt.from_numpy(obs).unsqueeze(0).float()))\n",
    "\n",
    "        r, obs_n, done, _, _ = env.step(action)\n",
    "\n",
    "        memory.store_transition(obs, action, r, obs_n, done)\n",
    "\n",
    "        cur_loss = 0\n",
    "        if (memory.counter > batch_size):\n",
    "            # Update network weights on batch\n",
    "            Q.optimizer.zero_grad()\n",
    "\n",
    "            states, actions, rewards, states_, dones = memory.sample_batch(batch_size)\n",
    "            indices = np.arange(batch_size)\n",
    "\n",
    "            q_pred = Q.forward(states)[indices, actions]\n",
    "            q_next = T.forward(states_).max(dim=1)[0]\n",
    "\n",
    "            q_next[dones] = 0.0\n",
    "            q_target = rewards + gamma*q_next\n",
    "\n",
    "            loss = Q.loss(q_target, q_pred)\n",
    "            loss.backward()\n",
    "            Q.optimizer.step()\n",
    "        \n",
    "        pbar.set_description(f\"Current Loss: {loss}\")\n",
    "        if i % update_freq == 0:\n",
    "            T.load_state_dict(Q.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-env",
   "language": "python",
   "name": "rl-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a926d3def179f663025bb8437b068ade0395ea661c618295799790ac4630b864"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
